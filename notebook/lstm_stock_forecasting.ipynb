{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Price Trend Prediction with LSTM  \n",
        "\n",
        "This notebook walks you through **end\u2011to\u2011end** LSTM forecasting on a stock's closing price using:\n",
        "- `yfinance` for data\n",
        "- Feature engineering: SMA(20/50) and RSI(14)\n",
        "- Train/validation split by time\n",
        "- Keras LSTM model with early stopping + model checkpoint\n",
        "- Plots for **Predictions vs Actual**, **Moving Averages**, and **RSI**\n",
        "\n",
        "> Tip: Run each cell from top to bottom the first time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# If running on a fresh environment, uncomment the next cell to install dependencies.\n",
        "# !pip install --upgrade pip\n",
        "# !pip install yfinance pandas numpy scikit-learn matplotlib tensorflow streamlit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, math, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Paths\n",
        "ARTIFACT_DIR = \"artifacts\"\n",
        "GRAPH_DIR = \"graphs\"\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "os.makedirs(GRAPH_DIR, exist_ok=True)\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== User-configurable parameters ====\n",
        "TICKER = \"AAPL\"                    # e.g., 'AAPL', 'MSFT', 'TCS.NS'\n",
        "START_DATE = \"2015-01-01\"\n",
        "END_DATE   = None                  # None = today\n",
        "LOOKBACK   = 60                    # Sequence length\n",
        "TEST_RATIO = 0.2                   # Last 20% of rows for test\n",
        "EPOCHS     = 25                    # Increase for better accuracy\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Moving Average & RSI parameters\n",
        "SMA_SHORT  = 20\n",
        "SMA_LONG   = 50\n",
        "RSI_PERIOD = 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Fetch price data ====\n",
        "if END_DATE is None:\n",
        "    END_DATE = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "df = yf.download(TICKER, start=START_DATE, end=END_DATE, auto_adjust=True, progress=False)\n",
        "if df.empty:\n",
        "    raise RuntimeError(\"No data fetched. Check the ticker or dates.\")\n",
        "\n",
        "df = df[['Close', 'Volume']].copy()\n",
        "df.reset_index(inplace=True)\n",
        "df.rename(columns={'Date':'date','Close':'close','Volume':'volume'}, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Feature engineering: SMA & RSI ====\n",
        "def compute_rsi(series: pd.Series, period: int = 14) -> pd.Series:\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0.0)\n",
        "    loss = -delta.clip(upper=0.0)\n",
        "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
        "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
        "    rs = avg_gain / (avg_loss + 1e-10)\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "df['sma_short'] = df['close'].rolling(SMA_SHORT).mean()\n",
        "df['sma_long']  = df['close'].rolling(SMA_LONG).mean()\n",
        "df['rsi']       = compute_rsi(df['close'], RSI_PERIOD)\n",
        "\n",
        "# Drop initial NaNs from indicators\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "print(\"Rows after indicators:\", len(df))\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Train/Test split by time & scaling ====\n",
        "n = len(df)\n",
        "test_size = int(n * TEST_RATIO)\n",
        "train_df = df.iloc[:-test_size].copy()\n",
        "test_df  = df.iloc[-test_size:].copy()\n",
        "\n",
        "# Feature matrix and target\n",
        "feature_cols = ['close', 'sma_short', 'sma_long', 'rsi']\n",
        "target_col   = 'close'\n",
        "\n",
        "X_train_raw = train_df[feature_cols].values\n",
        "X_test_raw  = test_df[feature_cols].values\n",
        "\n",
        "# Scale features and target separately\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_x.fit_transform(X_train_raw)\n",
        "X_test_scaled  = scaler_x.transform(X_test_raw)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(train_df[[target_col]].values)\n",
        "y_test_scaled  = scaler_y.transform(test_df[[target_col]].values)\n",
        "\n",
        "print(\"Train shape:\", X_train_scaled.shape, y_train_scaled.shape)\n",
        "print(\"Test shape :\", X_test_scaled.shape, y_test_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Sequence creation for LSTM ====\n",
        "def create_sequences(features, target, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(lookback, len(features)):\n",
        "        X.append(features[i - lookback:i])\n",
        "        y.append(target[i])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train, y_train = create_sequences(X_train_scaled, y_train_scaled, LOOKBACK)\n",
        "X_test, y_test   = create_sequences(X_test_scaled, y_test_scaled, LOOKBACK)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test :\", X_test.shape, \"y_test :\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Build LSTM model ====\n",
        "def build_model(input_shape, lr=1e-3):\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1)  # next close price\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='mse'\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), lr=LEARNING_RATE)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Train with early stopping & checkpoint ====\n",
        "ckpt_path = os.path.join(ARTIFACT_DIR, \"lstm_best_weights.keras\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save full model (optional)\n",
        "model_path = os.path.join(ARTIFACT_DIR, \"lstm_model.keras\")\n",
        "model.save(model_path)\n",
        "print(\"Saved weights to:\", ckpt_path)\n",
        "print(\"Saved model   to:\", model_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Predict & invert scaling ====\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "y_test_true = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Build a timeline index aligned with the test sequences\n",
        "test_index = test_df.iloc[LOOKBACK:]['date'].reset_index(drop=True)\n",
        "\n",
        "pred_df = pd.DataFrame({\n",
        "    'date': test_index,\n",
        "    'actual_close': y_test_true.flatten(),\n",
        "    'pred_close': y_pred.flatten()\n",
        "})\n",
        "\n",
        "pred_csv = os.path.join(ARTIFACT_DIR, f\"predictions_{TICKER}.csv\")\n",
        "pred_df.to_csv(pred_csv, index=False)\n",
        "pred_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== Metrics ====\n",
        "rmse = math.sqrt(mean_squared_error(pred_df['actual_close'], pred_df['pred_close']))\n",
        "mae  = mean_absolute_error(pred_df['actual_close'], pred_df['pred_close'])\n",
        "mape = np.mean(np.abs((pred_df['actual_close'] - pred_df['pred_close']) / pred_df['actual_close'])) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}  |  MAE: {mae:.4f}  |  MAPE: {mape:.2f}%\")\n",
        "\n",
        "# ==== Plot: Predictions vs Actual ====\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(pred_df['date'], pred_df['actual_close'], label='Actual')\n",
        "plt.plot(pred_df['date'], pred_df['pred_close'], label='Predicted')\n",
        "plt.title(f\"{TICKER}: Actual vs Predicted Close\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Price\"); plt.legend(); plt.tight_layout()\n",
        "\n",
        "pred_plot_path = os.path.join(GRAPH_DIR, f\"pred_vs_actual_{TICKER}.png\")\n",
        "plt.savefig(pred_plot_path, dpi=140)\n",
        "plt.show()\n",
        "\n",
        "# ==== Plot: Close with SMAs ====\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(df['date'], df['close'], label='Close')\n",
        "plt.plot(df['date'], df['sma_short'], label=f\"SMA{SMA_SHORT}\")\n",
        "plt.plot(df['date'], df['sma_long'], label=f\"SMA{SMA_LONG}\")\n",
        "plt.title(f\"{TICKER}: Close & Moving Averages\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Price\"); plt.legend(); plt.tight_layout()\n",
        "\n",
        "sma_plot_path = os.path.join(GRAPH_DIR, f\"sma_{TICKER}.png\")\n",
        "plt.savefig(sma_plot_path, dpi=140)\n",
        "plt.show()\n",
        "\n",
        "# ==== Plot: RSI ====\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(df['date'], df['rsi'], label='RSI')\n",
        "plt.axhline(70, linestyle='--'); plt.axhline(30, linestyle='--')\n",
        "plt.title(f\"{TICKER}: RSI({RSI_PERIOD})\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"RSI\"); plt.tight_layout()\n",
        "\n",
        "rsi_plot_path = os.path.join(GRAPH_DIR, f\"rsi_{TICKER}.png\")\n",
        "plt.savefig(rsi_plot_path, dpi=140)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\"-\", pred_plot_path)\n",
        "print(\"-\", sma_plot_path)\n",
        "print(\"-\", rsi_plot_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ==== (Optional) One-step ahead forecast for the next trading day ====\n",
        "# Use the last LOOKBACK rows from the FULL dataset (scaled) to predict the next close.\n",
        "# Recompute scalers on the entire data so that the latest point is included for demo.\n",
        "full_X = df[['close','sma_short','sma_long','rsi']].values\n",
        "full_y = df[['close']].values\n",
        "\n",
        "full_X_scaled = scaler_x.transform(full_X)  # use train-fitted scaler_x\n",
        "full_y_scaled = scaler_y.transform(full_y)  # use train-fitted scaler_y\n",
        "\n",
        "last_seq = full_X_scaled[-LOOKBACK:]\n",
        "next_scaled = model.predict(last_seq[np.newaxis, ...])\n",
        "next_price = scaler_y.inverse_transform(next_scaled)[0,0]\n",
        "\n",
        "print(f\"Next-day close (model one-step forecast): {next_price:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What to try next\n",
        "- Tune `EPOCHS`, `LOOKBACK`, `SMA` window sizes, and network depth.\n",
        "- Add more features (e.g., EMA, MACD, Bollinger Bands).\n",
        "- Try walk-forward validation to mimic live trading conditions.\n",
        "- Deploy the model behind an API or interactive dashboard (see `streamlit_app.py`).\n",
        "\n",
        "All artifacts (weights, model, and plots) are saved under `artifacts/` and `graphs/`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}